{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qBC_BPdmQgTWSd6n1B4d-pNAaATy_xVC","timestamp":1711865916486}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6PQSnsGeA2OH"},"source":["# 트랜스포머 (Transformer)\n","\n","* 참고: https://wikidocs.net/31379"]},{"cell_type":"markdown","metadata":{"id":"nbQ-h_XxBAiq"},"source":["* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n","* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n","* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RDiFPIdUBBS2"},"source":["## 포지셔널 인코딩"]},{"cell_type":"markdown","metadata":{"id":"rLqHf_4SEWoa"},"source":["* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n","* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n","* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n","* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"]},{"cell_type":"code","metadata":{"id":"SiO5c_HIFBAk","executionInfo":{"status":"ok","timestamp":1711876378910,"user_tz":-540,"elapsed":535,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def positional_encoding(dim, sentence_length):\n","    encoded_vec = np.array([pos / np.power(10000, 2 * i / dim) for pos in range(sentence_length) for i in range(dim)])\n","    encoded_vec[::2] = np.sin(encoded_vec[::2]) # 짝수 -> sin\n","    encoded_vec[1::2] = np.cos(encoded_vec[1::2]) # 홀수 -> cos\n","    return tf.constant(encoded_vec.reshape([sentence_length, dim]), dtype = tf.float32)"],"execution_count":116,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"099gUUxhAgy3"},"source":["## 레이어 정규화"]},{"cell_type":"markdown","metadata":{"id":"XCdips98yPuH"},"source":["*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n","*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"]},{"cell_type":"code","metadata":{"id":"TSJjxF86Aeg3","executionInfo":{"status":"ok","timestamp":1711877590597,"user_tz":-540,"elapsed":679,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def layer_norm(inputs, eps = 1e-6):\n","    feature_shape = inputs.get_shape()[-1:]\n","    mean = tf.keras.backend.mean(inputs, [-1], keepdims = True)\n","    std = tf.keras.backend.std(inputs, [-1], keepdims = True)\n","    beta = tf.Variable(tf.zeros(feature_shape), trainable = False)\n","    gamma = tf.Variable(tf.ones(feature_shape), trainable = False)\n","    return gamma * (inputs - mean) / (std + eps) + beta"],"execution_count":171,"outputs":[]},{"cell_type":"code","metadata":{"id":"km9ORxIun-MU","executionInfo":{"status":"ok","timestamp":1711877468853,"user_tz":-540,"elapsed":467,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def sublayer_connection(inputs, sublayer, dropout = 0.2):\n","    outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n","    return outputs"],"execution_count":169,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ppb7IxJ3diMC"},"source":["## 어텐션"]},{"cell_type":"markdown","metadata":{"id":"1JaU6MHgy9V2"},"source":["\n","\n","*   트랜스포머 모델의 핵심이 되는 부분\n","*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n","  1.   multi-head attention\n","      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n","      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n","      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n","  2.   self attention\n","      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n","      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n","      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n","      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n","\n","\n","\n","\n","*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kRyL0KDXi6ej"},"source":["### scaled-dot product attention 구현"]},{"cell_type":"markdown","metadata":{"id":"6HtmcgRR3Cr-"},"source":["* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n","* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n","* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"]},{"cell_type":"code","metadata":{"id":"ALEMzi4fdiSQ","executionInfo":{"status":"ok","timestamp":1711876379617,"user_tz":-540,"elapsed":708,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def scaled_dot_product_attention(query, key, value, masked = False):\n","    key_dim_size = float(key.get_shape().as_list()[-1])\n","    key = tf.transpose(key, perm = [0, 2, 1])\n","\n","    outputs = tf.matmul(query, key) / tf.sqrt(key_dim_size)\n","\n","    if masked:\n","        diag_vals = tf.ones_like(outputs[0, :, :])\n","        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # 아래 삼각행렬 남기고 위 삼각행렬은 padding 처리\n","        masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1])\n","        paddings = tf.ones_like(masks)*(-2**30) # 0이 아닌 아주 작은 값으로\n","        outputs = tf.where(tf.equal(masks, 0), paddings, outputs)\n","\n","    attention_map = tf.nn.softmax(outputs)\n","    return tf.matmul(attention_map, value)"],"execution_count":119,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yr20BxvVi-8b"},"source":["### multi-head attention 구현"]},{"cell_type":"markdown","metadata":{"id":"Gb5qflUH14-H"},"source":["* multi-head attention의 구현 과정\n","  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n","  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n","  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n","  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ooc3FAdQi_Gz","executionInfo":{"status":"ok","timestamp":1711876379617,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def multi_head_attention(query, key, value, num_units, heads, masked = False):\n","    query = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(query)\n","    key = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(key)\n","    value = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(value)\n","\n","    query = tf.concat(tf.split(query, heads, axis = -1), axis = 0)\n","    key = tf.concat(tf.split(key, heads, axis = -1), axis = 0)\n","    value = tf.concat(tf.split(value, heads, axis = -1), axis = 0)\n","\n","    attention_map = scaled_dot_product_attention(query, key, value, masked)\n","    attn_outputs = tf.concat(tf.split(attention_map, heads, axis = 0), axis = -1)\n","    attn_outputs = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(attn_outputs)\n","\n","    return attn_outputs"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78Zn5-fYITD4"},"source":["## 포지션-와이즈 피드 포워드 신경망"]},{"cell_type":"markdown","metadata":{"id":"-xxeG2xvo3ZN"},"source":["\n","\n","*   multi-head attention의 결과인 행렬을 입력받아 연산\n","*   일반적인 완전 연결 신경망(Dense layer)를 사용\n","*   position-wise FFNN은 인코더와 디코더에 모두 존재\n","\n"]},{"cell_type":"code","metadata":{"id":"0tSFd5OaITJ0","executionInfo":{"status":"ok","timestamp":1711876379617,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def feed_forward(inputs, num_units):\n","    feature_shape = inputs.get_shape()[-1]\n","    inner_layer = tf.keras.layers.Dense(num_units, activation = tf.nn.relu)(inputs)\n","    outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n","    return outputs"],"execution_count":121,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuccViYgBK6v"},"source":["## 인코더\n"]},{"cell_type":"markdown","metadata":{"id":"tG3MH0n1JVLz"},"source":["* 인코더는 하나의 어텐션을 사용\n","  + encoder self-attention (multi-head self-attention과 동일)"]},{"cell_type":"code","metadata":{"id":"m5T0pzBoAnn3","executionInfo":{"status":"ok","timestamp":1711876379617,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def encoder_module(inputs, model_dim, ffn_dim, heads):\n","    self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n","    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n","    return outputs\n","\n","def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n","    outputs = inputs\n","    for i in range(num_layers):\n","        outputs = encoder_module(outputs, model_dim, ffn_dim, heads)\n","\n","    return outputs"],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lcgHRcTEBQqg"},"source":["## 디코더"]},{"cell_type":"markdown","metadata":{"id":"cNj-6FLQwT4-"},"source":["* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n","  1. masked decoder self-attention\n","  2. encoder-decoder attention\n","  3. position-wise FFNN\n","\n","* 디코더에서는 2종류의 어텐션을 사용\n","  1.   masked decoder self-attention\n","    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n","    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n","    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n","  2.   encoder-decoder attention\n","    *   앞서 설명한 multi-head attention과 동일\n","\n"]},{"cell_type":"code","metadata":{"id":"2B05wr7aARcT","executionInfo":{"status":"ok","timestamp":1711876379617,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n","    masked_self_attn = sublayer_connection(inputs,\n","                                           multi_head_attention(inputs, inputs, inputs,\n","                                                                model_dim, heads, masked = True))\n","\n","    self_attn = sublayer_connection(masked_self_attn,\n","                                    multi_head_attention(masked_self_attn,\n","                                                         encoder_outputs,\n","                                                         encoder_outputs,\n","                                                         model_dim, heads))\n","    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n","    return outputs\n","\n","def decoder(inputs, encoder_outputs, model_dim, ffn_dim, heads, num_layers):\n","    outputs = inputs\n","    for i in range(num_layers):\n","        outputs = decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n","    return outputs"],"execution_count":123,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EtztlyUB1ERS"},"source":["## 트랜스포머를 활용한 챗봇"]},{"cell_type":"markdown","metadata":{"id":"6CGUIAzv6eWs"},"source":["### konlpy 라이브러리"]},{"cell_type":"markdown","metadata":{"id":"Ae0mHT49v5gy"},"source":["*    한글을 처리하기 위해 konlpy 라이브러리 설치"]},{"cell_type":"code","metadata":{"id":"U8yf75uG6hBW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711876384983,"user_tz":-540,"elapsed":5368,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}},"outputId":"0d8610cd-e03c-44eb-f17f-2fe82544d35d"},"source":["!pip install konlpy"],"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"rUMXvK5H1G9H"},"source":["### 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"miXrjR316mNb"},"source":["* 처리에 필요한 각종 변수 선언\n","* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n","\n"]},{"cell_type":"code","metadata":{"id":"SMjn5PfE1GZR","executionInfo":{"status":"ok","timestamp":1711876384983,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["import re\n","import tensorflow as tf\n","\n","filters = \"([~.,!?\\\"':;)(])\"\n","\n","# 토큰\n","PAD = '<PADDING>'\n","STD = '<START>'\n","END = '<END>'\n","UNK = '<UNKNOWN>'\n","\n","PAD_INDEX = 0\n","STD_INDEX = 1\n","END_INDEX = 2\n","UNK_INDEX = 3\n","\n","MARKER = [PAD, STD, END, UNK]\n","CHANGE_FILTER = re.compile(filters)"],"execution_count":125,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmRFuH2r6oNJ"},"source":["* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"CmrmdXkePWYb","executionInfo":{"status":"ok","timestamp":1711876796876,"user_tz":-540,"elapsed":517,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["\n","from sklearn.model_selection import train_test_split\n","\n","def load_data(data_path):\n","    data_df = pd.read_csv(data_path, header = 0)\n","    question, answer = list(data_df['Q']), list(data_df['A'])\n","    train_input, eval_input, train_label, eval_label = train_test_split(question, answer,\n","                                                                        test_size = 0.33,\n","                                                                        random_state = 111)\n","    return train_input, train_label, eval_input,  eval_label"],"execution_count":141,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHuOJHPtPXqq"},"source":["* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"]},{"cell_type":"code","metadata":{"id":"QtQL-AP06oSa","executionInfo":{"status":"ok","timestamp":1711876800362,"user_tz":-540,"elapsed":482,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def load_vocabulary(data_path):\n","    data_df = pd.read_csv(data_path, encoding = 'utf-8')\n","    question, answer = list(data_df['Q']), list(data_df['A'])\n","    if tokenize_as_morph:\n","        question = prepro_like_morphlized(question)\n","        answer = prepro_like_morphlized(answer)\n","\n","    data = []\n","    data.extend(question)\n","    data.extend(answer)\n","    words = data_tokenizer(data)\n","    words = list(set(words))\n","    words[:0] = MARKER\n","\n","    char2idx = {char:idx for idx, char in enumerate(words)}\n","    idx2char = {idx:char for idx, char in enumerate(words)}\n","    return char2idx, idx2char, len(char2idx)"],"execution_count":142,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5wYtpjv76r5q"},"source":["* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"-bQ3FOva6tg6","executionInfo":{"status":"ok","timestamp":1711876803045,"user_tz":-540,"elapsed":471,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["from konlpy.tag import Okt\n","\n","def prepro_like_morphlized(data):\n","    morph_analyzer = Okt()\n","    result_data = list()\n","    for seq in data:\n","        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n","        result_data.append(morphlized_seq)\n","    return result_data"],"execution_count":143,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vhsVp4pWPTR3"},"source":["* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"]},{"cell_type":"code","metadata":{"id":"otLI_RUfPR_g","executionInfo":{"status":"ok","timestamp":1711876805915,"user_tz":-540,"elapsed":784,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def data_tokenizer(data):\n","    words = []\n","    for sentence in data:\n","        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n","        for word in sentence.split():\n","            words.append(word)\n","    return [word for word in words if word]"],"execution_count":144,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OkKPA-Mx6uaC"},"source":["* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n","\n"]},{"cell_type":"code","metadata":{"id":"jK-yeSThPGsa","executionInfo":{"status":"ok","timestamp":1711876806449,"user_tz":-540,"elapsed":1,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["import numpy as np\n","\n","def enc_processing(value, dictionary):\n","    sequences_input_index = []\n","    sequences_length = []\n","\n","    if tokenize_as_morph:\n","        value = prepro_like_morphlized(value)\n","\n","    for sequence in value:\n","        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","        sequence_index = []\n","        for word in sequence.split():\n","            if dictionary.get(word) is not None:\n","                sequence_index.extend([dictionary[word]])\n","            else:\n","                sequence_index.extend([dictionary[UNK]])\n","        if len(sequence_index) > max_len:\n","            sequence_index = sequence_index[:max_len]\n","        sequences_length.append(len(sequence_index))\n","        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","        sequences_input_index.append(sequence_index)\n","    return np.asarray(sequences_input_index), sequences_length"],"execution_count":145,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4mM57_FPIg7"},"source":["* decoder의 입력을 구성하기 위한 함수 `dec_output_processing()` 선언"]},{"cell_type":"code","metadata":{"id":"cX_NpcTq6vw6","executionInfo":{"status":"ok","timestamp":1711876807900,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def dec_output_processing(value, dictionary):\n","    sequences_output_index = []\n","    sequences_length = []\n","\n","    if tokenize_as_morph:\n","        value = prepro_like_morphlized(value)\n","\n","    for sequence in value:\n","        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","        sequence_index = []\n","        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n","        if len(sequence_index) > max_len:\n","            sequence_index = sequence_index[:max_len]\n","        sequences_length.append(len(sequence_index))\n","        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","        sequences_output_index.append(sequence_index)\n","    return np.asarray(sequences_output_index), sequences_length"],"execution_count":146,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otsTEt4FPLJX"},"source":["* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"]},{"cell_type":"code","metadata":{"id":"eeP0PWHEPMma","executionInfo":{"status":"ok","timestamp":1711876808635,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def dec_target_processing(value, dictionary):\n","    sequences_target_index = []\n","\n","    if tokenize_as_morph:\n","        value = prepro_like_morphlized(value)\n","\n","    for sequence in value:\n","        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n","        sequence_index = [dictionary[word] for word in sequence.split()]\n","        if len(sequence_index) > max_len:\n","            sequence_index = sequence_index[:max_len - 1] + [dictionary[END]]\n","        else:\n","            sequence_index += [dictionary[END]]\n","        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n","        sequences_target_index.append(sequence_index)\n","    return np.asarray(sequences_target_index)"],"execution_count":147,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tb9vVUng6xDq"},"source":["* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n","* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n","* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n","\n"]},{"cell_type":"code","metadata":{"id":"uAlKV4xF62Uf","executionInfo":{"status":"ok","timestamp":1711876809422,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def train_input_fn(train_input_enc, train_output_enc, train_target_dec, batch_size):\n","    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_input_enc, train_output_enc, train_target_dec))\n","    dataset = dataset.shuffle(buffer_size = len(train_input_enc))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(rearrange)\n","    dataset = dataset.repeat()\n","    iterator = dataset.make_one_shot_iterator()\n","    return iterator.get_next()\n","\n","def eval_input_fn(eval_input_enc, eval_output_enc, eval_target_dec, batch_size):\n","    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((eval_input_enc, eval_output_enc, eval_target_dec))\n","    dataset = dataset.shuffle(buffer_size = len(eval_input_enc))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(rearrange)\n","    dataset = dataset.repeat()\n","    iterator = dataset.make_one_shot_iterator()\n","    return iterator.get_next()\n","\n","def rearrange(input, output, target):\n","    features = {'input':input, 'output':output}\n","    return features, target"],"execution_count":148,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"is-GhUDN62xC"},"source":["* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n","* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"]},{"cell_type":"code","metadata":{"id":"jCfwWXhb64Cc","executionInfo":{"status":"ok","timestamp":1711878353304,"user_tz":-540,"elapsed":548,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def pred2string(value, dictionary):\n","    sentence_string = []\n","    is_finished = False\n","    print(value)\n","\n","    for v in value:\n","      print(v['indexs'])\n","        sentence_string = [dictionary[index] for index in v['indexs']]\n","\n","    answer = \"\"\n","    for word in sentence_string:\n","        if word == END:\n","            is_finished = True\n","            break\n","\n","        if word != PAD and word != END:\n","            answer += word\n","            answer += \" \"\n","    print(answer)\n","    return answer, is_finished"],"execution_count":188,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwp9Nnwz7UoG"},"source":["* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n","* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"]},{"cell_type":"code","metadata":{"id":"-T536MdU7Taq","executionInfo":{"status":"ok","timestamp":1711876916123,"user_tz":-540,"elapsed":105045,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["import pandas as pd\n","\n","tokenize_as_morph = True\n","\n","data_path = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv'\n","\n","char2idx, idx2char, len_vocab = load_vocabulary(data_path)\n","train_input, train_label, eval_input, eval_label = load_data(data_path)"],"execution_count":150,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7cVd7AOKinqn"},"source":["### 모델 구성"]},{"cell_type":"markdown","metadata":{"id":"hqLJ0a6r49yi"},"source":["* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"]},{"cell_type":"code","metadata":{"id":"CNeeXoZginvj","executionInfo":{"status":"ok","timestamp":1711878356650,"user_tz":-540,"elapsed":484,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["def model(features, labels, mode, params):\n","    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n","    EVAL = mode == tf.estimator.ModeKeys.EVAL\n","    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n","\n","    position_encode = positional_encoding(params['embedding_size'], params['max_len'])\n","    if params['xavier_initializer']:\n","        embedding_initializer = 'glorot_normal'\n","    else:\n","        embedding_initializer = 'uniform'\n","\n","    embedding = tf.keras.layers.Embedding(params['len_vocab'],\n","                                          params['embedding_size'],\n","                                          embeddings_initializer = embedding_initializer)\n","\n","    x_embedded_matrix = embedding(features['input']) + position_encode\n","    y_embedded_matrix = embedding(features['output']) + position_encode\n","\n","    encoder_outputs = encoder(x_embedded_matrix, params['model_hidden_size'], params['ffn_hidden_size'],\n","                              params['attention_head_size'], params['layer_size'])\n","    decoder_outputs = decoder(y_embedded_matrix, encoder_outputs, params['model_hidden_size'],\n","                              params['ffn_hidden_size'], params['attention_head_size'], params['layer_size'])\n","\n","    logits = tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n","    predict = tf.argmax(logits, 2)\n","\n","    if PREDICT:\n","        predictions = {'indexs':predict,\n","                       'logits':logits}\n","        return tf.estimator.EstimatorSpec(mode, predictions = predictions)\n","\n","    labels_ = tf.one_hot(labels, params['len_vocab'])\n","    loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels_))\n","    accuracy = tf.compat.v1.metrics.accuracy(labels = labels, predictions = predict)\n","\n","    metrics = {'accuracy':accuracy}\n","    tf.summary.scalar('accuracy', accuracy[1])\n","\n","    if EVAL:\n","        return tf.estimator.EstimatorSpec(mode, loss = loss, eval_metric_ops = metrics)\n","    assert TRAIN\n","\n","    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = params['learning_rate'])\n","    train_op = optimizer.minimize(loss, global_step = tf.compat.v1.train.get_global_step())\n","    return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = train_op)"],"execution_count":189,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7PrLEWE1JCs"},"source":["### 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"Gy_Opm_A7DKC"},"source":["*   필요한 각종 인자들을 설정\n","*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"]},{"cell_type":"code","metadata":{"id":"CKGYuqmH6_kj","executionInfo":{"status":"ok","timestamp":1711877427159,"user_tz":-540,"elapsed":546,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["max_len = 25\n","epoch = 5000\n","batch_size = 256\n","embedding_size = 100\n","model_hidden_size = 100\n","ffn_hidden_size = 100\n","attention_head_size = 100\n","lr = 0.001\n","layer_size = 3\n","xavier_initializer = True"],"execution_count":166,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aaXalEy57ODq"},"source":["*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n","*   평가 데이터에도 동일하게 가공"]},{"cell_type":"code","metadata":{"id":"NWlgWWIq1KSh","executionInfo":{"status":"ok","timestamp":1711877265443,"user_tz":-540,"elapsed":154372,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}}},"source":["\n","train_input_enc, train_input_enc_length = enc_processing(train_input, char2idx)\n","train_output_dec, train_output_dec_length = dec_output_processing(train_input, char2idx)\n","train_target_dec = dec_target_processing(train_label, char2idx)\n","\n","eval_input_enc, eval_input_enc_length = enc_processing(eval_input, char2idx)\n","eval_output_dec, eval_output_dec_length = dec_output_processing(eval_input, char2idx)\n","eval_target_dec = dec_target_processing(eval_label, char2idx)"],"execution_count":158,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZGgZzWs7Mr7"},"source":["* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n","* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"]},{"cell_type":"code","metadata":{"id":"B9vjc3Ck7F4J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711878360500,"user_tz":-540,"elapsed":595,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}},"outputId":"4621a361-fc47-48ab-dfa3-c34218cb0d69"},"source":["transformer = tf.estimator.Estimator(\n","    model_fn = model,\n","    params = {'embedding_size': embedding_size,\n","              'model_hidden_size': model_hidden_size,\n","              'ffn_hidden_size': ffn_hidden_size,\n","              'attention_head_size': attention_head_size,\n","              'learning_rate': lr,\n","              'len_vocab': len_vocab,\n","              'layer_size': layer_size,\n","              'max_len': max_len,\n","              'xavier_initializer': xavier_initializer}\n",")"],"execution_count":190,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmph4dvy803\n"]}]},{"cell_type":"markdown","metadata":{"id":"wl_pwUiw7INZ"},"source":["* 학습한 모델을 사용해 챗봇을 사용\n","* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n","* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"]},{"cell_type":"code","metadata":{"id":"COO-0PcS7Hy5","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"error","timestamp":1711878769168,"user_tz":-540,"elapsed":406810,"user":{"displayName":"‍황서진[재학 / 컴퓨터.전자시스템공학전공]","userId":"07764430498645957034"}},"outputId":"c07b4b3e-581f-499f-d728-d46915a2487e"},"source":["transformer.train(input_fn = lambda: train_input_fn(train_input_enc, train_output_dec, train_target_dec, batch_size), steps = epoch)\n","eval_result = transformer.evaluate(input_fn = lambda: eval_input_fn(train_input_enc, eval_output_dec, eval_target_dec, batch_size))\n","\n","print('{accuracy : 0.3f}'.format(**eval_result))"],"execution_count":191,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \"\"\"\n\u001b[0;32m--> 778\u001b[0;31m     return self._sess.run(\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         return self._sess.run(\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0mrun_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     outputs = _WrappedSession.run(\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    973\u001b[0m                          run_metadata_ptr)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                              feed_dict_tensor, options, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                            run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                                       target_list, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1478\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-191-e37251694509>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_output_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{accuracy : 0.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1186\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                                            self.config)\n\u001b[1;32m   1218\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0m\u001b[1;32m   1220\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                              saving_listeners)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                   output_dir=self._config.model_dir))\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m     with training.MonitoredTrainingSession(\n\u001b[0m\u001b[1;32m   1515\u001b[0m         \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0mis_chief\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_chief\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[0;34m(self, exception_type)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session is already closed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         logging.error(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;31m# We intentionally suppress exceptions from the close() here since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         logging.error(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         logging.error(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_CloseSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"MNcrVf2z1LSM"},"source":["### 예측"]},{"cell_type":"markdown","metadata":{"id":"R5lY9DrW8eSK"},"source":["* 학습한 모델을 사용해 챗봇을 사용\n","* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n","* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"]},{"cell_type":"code","metadata":{"id":"N9IQaBx4Qw8J"},"source":["def chatbot(sentence):\n","    pred_input_enc, pred_input_enc_length = enc_processing([sentence], char2idx)\n","    pred_output_dec, pred_output_dec_length = dec_output_processing([\"\"], char2idx)\n","    pred_target_dec = dec_target_processing([\"\"], char2idx)\n","\n","    for i in range(max_len):\n","        if i > 0:\n","            pred_output_dec, pred_output_dec_length = dec_output_processing([answer], char2idx)\n","            pred_target_dec = dec_target_processing([answer], char2idx)\n","\n","        predictions = transformer.predict(input_fn = lambda: eval_input_fn(pred_input_enc, pred_output_dec, pred_target_dec, 1))\n","\n","        answer, finished = pred2string(predictions, idx2char)\n","\n","        if finished:\n","            break\n","\n","    return answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjHZKvJ31MAU"},"source":["chatbot(\"안녕?\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mjRZwyLQ_gP"},"source":["chatbot(\"너 누구냐?\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7AJCsXRTqJx"},"source":["chatbot(\"뭐 먹었어?\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_M8mfoUfeAWQ"},"source":["chatbot('놀고 싶다')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5mrdGRaem6v"},"source":["chatbot('이제 그만 잘래')"],"execution_count":null,"outputs":[]}]}